{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microsoft L2R Datasets\n",
    "[MS datasets](https://www.microsoft.com/en-us/research/project/mslr/)\n",
    "\n",
    "`MSLR-WEB30k`と`MSLR-WEB10K`といった二つの大きなデータセットを公開している。\n",
    "\n",
    "## Datasets Desc\n",
    "+ クエリとURLはIDにより表現されている\n",
    "+ 特徴量と関連度の程度のペアで表現されている\n",
    "\n",
    "(1) 関連度はすでに利用されなくなった、商用Web検索エンジンのラベリングを利用している。\n",
    "関連度は0~4のラベルで表現されている。\n",
    "\n",
    "(2) 素性はMicrosoftにより設定されているが、大抵の検索エンジンで利用されているもの。\n",
    "\n",
    "関連度と素性の組み、クエリIDは次のように表現されている。\n",
    "\n",
    "```dat\n",
    "0 qid:1 1:3 2:0 3:2 4:2 … 135:0 136:0\n",
    "2 qid:1 1:3 2:3 3:0 4:0 … 135:0 136:0\n",
    "...\n",
    "```\n",
    "\n",
    "## Feature List\n",
    "`query-url`ペアは136次元のベクトルにより表現されている。大別したものを表に表す。\n",
    "\n",
    "| feature name | desc |\n",
    "|:-----------------|:-------|\n",
    "| covered query term number | 文書に含まれるクエリに利用された単語数 |\n",
    "| covered query term ratio | 文書に含まれるクエリに利用された単語数 / クエリの単語数 |\n",
    "| stream length | 文字列長？ |\n",
    "| IDF | 逆文書頻度 クエリの単語を含む文書数の逆数だったはず |\n",
    "| sum of term freq | クエリの単語をいくつ含むか　|\n",
    "| min of term freq | クエリに含まれる単語の中で、文書中で最も出現しなかった単語の出現数 |\n",
    "| max of term freq | 上の逆バージョン　|\n",
    "| mean of term freq | 上の平均バージョン　|\n",
    "| variance of term freq | 上の分散バージョン |\n",
    "| sum of tf\\* idf | クエリの単語のTF-IDFの総和 |\n",
    "| boolean model | 文書とクエリの論理値モデルのスコア |\n",
    "| vector space model | 文書とクエリのベクトル空間モデルのスコア |\n",
    "| BM25 | okapiのやつ？ |\n",
    "\n",
    "端的に言ってしまえば、いろいろなスコアを文書について設定して、それぞれのスコアから`Ground-truth`と最も矛盾が少なく済むように素性に対する重みベクトルを決定することを目標としている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ利用\n",
    "ダウンロードできるデータの形式が特殊なので、CSV形式に変換するスクリプトを考える。\n",
    "\n",
    "```\n",
    "0 qid:1 1:3 2:0 3:2 4:2 … 135:0 136:0\n",
    "```\n",
    "\n",
    "一行あたりの表現。半角スペースで分割されている。\n",
    "最初の数値は関連度、2番目はクエリID、それ以降はそれぞれの素性の`次元:値`となっている。\n",
    "\n",
    "ひっくり返してラベルを変換した時に\n",
    "0関連度集合と1関連度集合の直積\n",
    "次に０と2の直積... としていくと無駄がない\n",
    "\n",
    "ループの並列処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numba import jit\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_dat(filepath=\"./datasets/Fold1/train.txt\", show_proc=True):\n",
    "    \"\"\"DataFrameに読み込ませるリストを返す\"\"\"\n",
    "    rows = []\n",
    "    _append = rows.append # 高速化\n",
    "    with  open(filepath, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    for i, line in enumerate(lines):\n",
    "        if show_proc and i % 100000 == 0:\n",
    "            print(\"{0}~{1} lines are being precessed...\".format(i, i + 99999))\n",
    "        li = line.split()\n",
    "        li_dict = { \"rel\": li[0] }\n",
    "        for idx in range(1, len(li)):\n",
    "            kv = li[idx].split(\":\")\n",
    "            li_dict[kv[0]] = kv[1] # 型変換はpandasで\n",
    "        _append(li_dict)\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# パフォーマンスの計測\n",
    "def fib(n):\n",
    "    if n == 0: return 1\n",
    "    if n == 1: return 1\n",
    "    if n >= 2: return fib(n-1) + fib(n-2)\n",
    "\n",
    "start = time.time()\n",
    "fib(10)\n",
    "time_elapsed = time.time() - start\n",
    "print(\"time_slapsed: {0} sec\".format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 読み込み速度の計測\n",
    "# s1 = time.time()\n",
    "# rows_ = naive_read_dat()\n",
    "# t1 = time.time() - s1\n",
    "# print(\"time_slapsed: {0} sec\".format(t1))\n",
    "\n",
    "s2 = time.time()\n",
    "rows = read_dat()\n",
    "t2 = time.time() - s2\n",
    "print(\"time_slapsed: {0} sec\".format(t2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  方針\n",
    "学習器の出力はdf[\"rel\"]の予測値。その予測値は0~4を離散的に取りうる。\n",
    "同じクエリに関連するドキュメント対を比較し、`pairwise preference`を関連度から取得する。\n",
    "\n",
    "### RankingSVM\n",
    "訓練データ$D = \\{(\\hat{d_{i}}, \\check{d_{j}})\\}_{i=1}^{N}$は、クエリに関連するドキュメントの対$(\\hat{d_{i}}, \\check{d_{j}})$を$N$件持っている。ただし、$\\hat{d_{i}}$は$\\check{d_{j}}$よりも関連度が高い文書である。\n",
    "それぞれの文書がベクトル$\\hat{x_{i}}$、$\\check{x_{j}}$で表される時、RankingSVMは次のような最適化問題を考える。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "min: L(w, \\xi) = \\frac{1}{2}w^{T}w + C\\sum_{i}^{N}\\xi_{i}\n",
    "$$\n",
    "$$\n",
    "s.t. {w}^{T}\\phi(\\hat{x_{i}}) \\ge w^{T}\\phi(\\check{x_{j}}) + 1 - \\xi_{i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習された重み$\\bf{w^{*}}$を利用して、ランキング関数は次のように表現される。\n",
    "\n",
    "$$\n",
    "f(d) = w^{*T}\\phi(x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実装\n",
    "次のページを参考にした。\n",
    "\n",
    "[ranking svm](https://gist.github.com/fabianp/2020955)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rows)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "from sklearn import svm, linear_model, cross_validation\n",
    "\n",
    "def transform_pairwise(X, y):\n",
    "    \"\"\"文書集合の関連度をみて、pairwise preferenceに変換する\n",
    "    \n",
    "    注意するべきは、Gistの実装とは違い、複数のクエリを考える必要があること\n",
    "    \"\"\"\n",
    "    X_new = []\n",
    "    y_new = []\n",
    "    y = np.asarray(y)\n",
    "    if y.ndim == 1:\n",
    "        y = np.c_[y, np.ones(y.shape[0])]\n",
    "    comb = itertools.combinations(range(X.shape[0]), 2)\n",
    "    for k, (i, j) in enumerate(comb):\n",
    "        if y[i, 0] == y[j, 0] or y[i, 1] != y[j, 1]:\n",
    "            continue\n",
    "        X_new.append(X[i] - X[j])\n",
    "        y_new.append(np.sign(y[i, 0] - y[j, 0]))\n",
    "        # y_newの符号に偏りが出ないようにする\n",
    "        if y_new[-1] != (-1) ** k:\n",
    "            y_new[-1] = - y_new[-1]\n",
    "            X_new[-1] = - X_new[-1]\n",
    "    return np.asarray(X_new), np.asarray(y_new).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5fdfc6b5255c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mX_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_pairwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/SaigusaMoriaki/anaconda/lib/python3.5/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(arr, values, axis)\u001b[0m\n\u001b[1;32m   4584\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4585\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions"
     ]
    }
   ],
   "source": [
    "grouped = df.groupby(\"qid\")\n",
    "cols = df.columns\n",
    "X_feat = list(cols[:-2]) # -2, -1番目はqidとrel\n",
    "y_feat = cols[-1] # rel\n",
    "# より小さなデータセットで試す n_iter = 10\n",
    "# data_X, data_y\n",
    "# g は[0]がグループのインデックス, [1]がpd.DataFrame\n",
    "X_train = np.array([])\n",
    "y_train = np.array([])\n",
    "X_test = np.array([])\n",
    "y_test = np.array([])\n",
    "for _, g in enumerate(grouped):\n",
    "    tmp = g[1]\n",
    "    if _ <= 10:\n",
    "        X = tmp[X_feat].applymap(float).values\n",
    "        y = tmp[y_feat].map(float)\n",
    "        X_new, y_new = transform_pairwise(X, y)\n",
    "        if _ <= 9:\n",
    "            X_train = np.append(X_train, X_new, axis=0) # stackに\n",
    "            y_train = np.append(y_train, y_new)\n",
    "        else:\n",
    "            X_test = np.append(X_test, X_new, axis=0)\n",
    "            y_test = np.append(y_test, y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC() # linearSVMに変更\n",
    "clf.fit(X_new, y_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次はクエリごとにデータセットを作成するのと、テストデータについてうまく学習できているかを確認するところから"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "[クエリのメタデータがある？](https://www.microsoft.com/en-us/research/project/letor-learning-rank-information-retrieval/)\n",
    "\n",
    "+ 自分がやりたいことは、クエリの素性を利用する。クエリのメタデータを調査。\n",
    "+ 青本でカーネル関数なんたるかチェック\n",
    "\n",
    "カーネルは、ベクトルを特徴空間に飛ばしたあとの内積\n",
    "RBFカーネルは、\n",
    "\n",
    "$x$, $y$\n",
    "\n",
    "$$\n",
    "\\phi(x) = x\n",
    "$$\n",
    "\n",
    "の場合は、\n",
    "\n",
    "写像したあとの内積が等しくなるような関数がカーネル\n",
    "\n",
    "$$\n",
    "K(x, y) = \\phi(x)^{T}\\phi(y)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\phi(x) = ? \\\\\n",
    "K(x, y) = ... = exp(ガウス)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
