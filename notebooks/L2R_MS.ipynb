{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microsoft L2R Datasets\n",
    "[MS datasets](https://www.microsoft.com/en-us/research/project/mslr/)\n",
    "\n",
    "`MSLR-WEB30k`と`MSLR-WEB10K`といった二つの大きなデータセットを公開している。\n",
    "\n",
    "## Datasets Desc\n",
    "+ クエリとURLはIDにより表現されている\n",
    "+ 特徴量と関連度の程度のペアで表現されている\n",
    "\n",
    "(1) 関連度はすでに利用されなくなった、商用Web検索エンジンのラベリングを利用している。\n",
    "関連度は0~4のラベルで表現されている。\n",
    "\n",
    "(2) 素性はMicrosoftにより設定されているが、大抵の検索エンジンで利用されているもの。\n",
    "\n",
    "関連度と素性の組み、クエリIDは次のように表現されている。\n",
    "\n",
    "```dat\n",
    "0 qid:1 1:3 2:0 3:2 4:2 … 135:0 136:0\n",
    "2 qid:1 1:3 2:3 3:0 4:0 … 135:0 136:0\n",
    "...\n",
    "```\n",
    "\n",
    "## Feature List\n",
    "`query-url`ペアは136次元のベクトルにより表現されている。大別したものを表に表す。\n",
    "\n",
    "| feature name | desc |\n",
    "|:-----------------|:-------|\n",
    "| covered query term number | 文書に含まれるクエリに利用された単語数 |\n",
    "| covered query term ratio | 文書に含まれるクエリに利用された単語数 / クエリの単語数 |\n",
    "| stream length | ??? |\n",
    "| IDF | 逆文書頻度 クエリの単語を含む文書数の逆数だったはず |\n",
    "| sum of term freq | クエリの単語をいくつ含むか　|\n",
    "| min of term freq | クエリに含まれる単語の中で、文書中で最も出現しなかった単語の出現数 |\n",
    "| max of term freq | 上の逆バージョン　|\n",
    "| mean of term freq | 上の平均バージョン　|\n",
    "| variance of term freq | 上の分散バージョン |\n",
    "| sum of tf\\* idf | クエリの単語のTF-IDFの総和 |\n",
    "| boolean model | 文書とクエリの論理値モデルのスコア |\n",
    "| vector space model | 文書とクエリのベクトル空間モデルのスコア |\n",
    "| BM25 | okapiのやつ？ |\n",
    "\n",
    "端的に言ってしまえば、いろいろなスコアを文書について設定して、それぞれのスコアから`Ground-truth`と最も矛盾が少なく済むように素性に対する重みベクトルを決定することを目標としている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ利用\n",
    "ダウンロードできるデータの形式が特殊なので、CSV形式に変換するスクリプトを考える。\n",
    "\n",
    "```\n",
    "0 qid:1 1:3 2:0 3:2 4:2 … 135:0 136:0\n",
    "```\n",
    "\n",
    "一行あたりの表現。半角スペースで分割されている。\n",
    "最初の数値は関連度、2番目はクエリID、それ以降はそれぞれの素性の`次元:値`となっている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numba import jit\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_dat(filepath=\"./datasets/Fold1/train.txt\", show_proc=True):\n",
    "    \"\"\"DataFrameに読み込ませるリストを返す\"\"\"\n",
    "    rows = []\n",
    "    _append = rows.append # 高速化\n",
    "    with  open(filepath, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    for i, line in enumerate(lines):\n",
    "        if show_proc and i % 100000 == 0:\n",
    "            print(\"{0}~{1} lines are being precessed...\".format(i, i + 99999))\n",
    "        li = line.split()\n",
    "        li_dict = { \"rel\": li[0] }\n",
    "        for idx in range(1, len(li)):\n",
    "            kv = li[idx].split(\":\")\n",
    "            li_dict[kv[0]] = kv[1] # 型変換はpandasで\n",
    "        _append(li_dict)\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_slapsed: 7.605552673339844e-05 sec\n"
     ]
    }
   ],
   "source": [
    "# パフォーマンスの計測\n",
    "def fib(n):\n",
    "    if n == 0: return 1\n",
    "    if n == 1: return 1\n",
    "    if n >= 2: return fib(n-1) + fib(n-2)\n",
    "\n",
    "start = time.time()\n",
    "fib(10)\n",
    "time_elapsed = time.time() - start\n",
    "print(\"time_slapsed: {0} sec\".format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0~99999 lines are being precessed...\n",
      "100000~199999 lines are being precessed...\n",
      "200000~299999 lines are being precessed...\n",
      "300000~399999 lines are being precessed...\n",
      "400000~499999 lines are being precessed...\n",
      "500000~599999 lines are being precessed...\n",
      "600000~699999 lines are being precessed...\n",
      "700000~799999 lines are being precessed...\n",
      "time_slapsed: 62.31073808670044 sec\n"
     ]
    }
   ],
   "source": [
    "# 読み込み速度の計測\n",
    "# s1 = time.time()\n",
    "# rows_ = naive_read_dat()\n",
    "# t1 = time.time() - s1\n",
    "# print(\"time_slapsed: {0} sec\".format(t1))\n",
    "\n",
    "s2 = time.time()\n",
    "rows = read_dat()\n",
    "t2 = time.time() - s2\n",
    "print(\"time_slapsed: {0} sec\".format(t2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  方針\n",
    "学習器の出力はdf[\"rel\"]の予測値。その予測値は0~4を離散的に取りうる。\n",
    "同じクエリに関連するドキュメント対を比較し、`pairwise preference`を関連度から取得する。\n",
    "\n",
    "### RankingSVM\n",
    "訓練データ$D = \\{(\\hat{d_{i}}, \\check{d_{j}})\\}_{i=1}^{N}$は、クエリに関連するドキュメントの対$(\\hat{d_{i}}, \\check{d_{j}})$を$N$件持っている。ただし、$\\hat{d_{i}}$は$\\check{d_{j}}$よりも関連度が高い文書である。\n",
    "それぞれの文書がベクトル$\\hat{x_{i}}$、$\\check{x_{j}}$で表される時、RankingSVMは次のような最適化問題を考える。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "min: L(w, \\xi) = \\frac{1}{2}w^{T}w + C\\sum_{i}^{N}\\xi_{i}\n",
    "$$\n",
    "$$\n",
    "s.t. {w}^{T}\\phi(\\hat{x_{i}}) \\ge w^{T}\\phi(\\check{x_{j}}) + 1 - \\xi_{i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習された重み$\\bf{w^{*}}$を利用して、ランキング関数は次のように表現される。\n",
    "\n",
    "$$\n",
    "f(d) = w^{*T}\\phi(x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実装\n",
    "次のページを参考にした。\n",
    "\n",
    "[ranking svm](https://gist.github.com/fabianp/2020955)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>...</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>qid</th>\n",
       "      <th>rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.941469</td>\n",
       "      <td>20.59276</td>\n",
       "      <td>...</td>\n",
       "      <td>1.084169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.78795</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994425</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.995455</td>\n",
       "      <td>20.885118</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.167248</td>\n",
       "      <td>0</td>\n",
       "      <td>75.339929</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.851903</td>\n",
       "      <td>0</td>\n",
       "      <td>0.720414</td>\n",
       "      <td>0</td>\n",
       "      <td>0.842789</td>\n",
       "      <td>18.140878</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7.736505</td>\n",
       "      <td>0</td>\n",
       "      <td>61.124916</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.989585</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.995185</td>\n",
       "      <td>15.572998</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.167248</td>\n",
       "      <td>0</td>\n",
       "      <td>3.900733</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980551</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.989938</td>\n",
       "      <td>7.802556</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.167248</td>\n",
       "      <td>0</td>\n",
       "      <td>6.941327</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1 10 100       101 102       103 104       105        106       107 ...  \\\n",
       "0  3  1   1         1   1         0   0         1  12.941469  20.59276 ...   \n",
       "1  3  1   1  0.994425   0         1   0  0.995455  20.885118         0 ...   \n",
       "2  3  1   1  0.851903   0  0.720414   0  0.842789  18.140878         0 ...   \n",
       "3  3  1   1  0.989585   0         1   0  0.995185  15.572998         0 ...   \n",
       "4  3  1   1  0.980551   0         1   0  0.989938   7.802556         0 ...   \n",
       "\n",
       "         92        93 94         95 96 97 98 99 qid rel  \n",
       "0  1.084169         0  0    2.78795  1  1  0  0   1   2  \n",
       "1         0  1.167248  0  75.339929  1  0  1  0   1   2  \n",
       "2         0  7.736505  0  61.124916  1  0  0  0   1   0  \n",
       "3         0  1.167248  0   3.900733  1  0  1  0   1   2  \n",
       "4         0  1.167248  0   6.941327  1  0  1  0   1   1  \n",
       "\n",
       "[5 rows x 138 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(rows)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/SaigusaMoriaki/anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "from sklearn import svm, linear_model, cross_validation\n",
    "\n",
    "def transform_pairwise(X, y):\n",
    "    \"\"\"文書集合の関連度をみて、pairwise preferenceに変換する\n",
    "    \n",
    "    注意するべきは、Gistの実装とは違い、複数のクエリを考える必要があること\n",
    "    \"\"\"\n",
    "    X_new = []\n",
    "    y_new = []\n",
    "    y = np.asarray(y)\n",
    "    if y.ndim == 1:\n",
    "        y = np.c_[y, np.ones(y.shape[0])]\n",
    "    comb = itertools.combinations(range(X.shape[0]), 2)\n",
    "    for k, (i, j) in enumerate(comb):\n",
    "        if y[i, 0] == y[j, 0] or y[i, 1] != y[j, 1]:\n",
    "            continue\n",
    "        X_new.append(X[i] - X[j])\n",
    "        y_new.append(np.sign(y[i, 0] - y[j, 0]))\n",
    "        # y_newの符号に偏りが出ないようにする\n",
    "        if y_new[-1] != (-1) ** k:\n",
    "            y_new[-1] = - y_new[-1]\n",
    "            X_new[-1] = - X_new[-1]\n",
    "    return np.asarray(X_new), np.asarray(y_new).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped = df.groupby(\"qid\")\n",
    "cols = df.columns\n",
    "X_feat = list(cols[:-2]) # -2, -1番目はqidとrel\n",
    "y_feat = cols[-1] # rel\n",
    "# より小さなデータセットで試す n_iter = 10\n",
    "# data_X, data_y\n",
    "# g は[0]がグループのインデックス, [1]がpd.DataFrame\n",
    "X_train = np.array([])\n",
    "y_train = np.array([])\n",
    "X_test = np.array([])\n",
    "y_test = np.array([])\n",
    "for _, g in enumerate(grouped):\n",
    "    tmp = g[1]\n",
    "    if _ <= 10:\n",
    "        X = tmp[X_feat].applymap(float).values\n",
    "        y = tmp[y_feat].map(float)\n",
    "        X_new, y_new = transform_pairwise(X, y)\n",
    "        if _ <= 9:\n",
    "            X_train = np.append(X_train, X_new, axis=0)\n",
    "            y_train = np.append(y_train, y_new)\n",
    "        else:\n",
    "            X_test = np.append(X_test, X_new, axis=0)\n",
    "            y_test = np.append(y_test, y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1., -1.,  1., ...,  1., -1., -1.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf = svm.SVC()\n",
    "# clf.fit(X_new, y_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次はクエリごとにデータセットを作成するのと、テストデータについてうまく学習できているかを確認するところから"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
