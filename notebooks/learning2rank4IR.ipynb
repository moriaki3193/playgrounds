{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning to Rank for IR\n",
    "[original PDF](http://wwwconference.org/www2009/pdf/T7A-LEARNING%20TO%20RANK%20TUTORIAL.pdf)\n",
    "\n",
    "## This tutorial\n",
    "+ IRのための順序学習\n",
    "  - そのほかの分野でのランキング問題ではない\n",
    "+ Supervised learning\n",
    "  - unsupervised, semi-supervised学習ではない\n",
    "+ ベクトル空間で学ぶ\n",
    "  - グラフやそのほかのデータ構造を扱うものではない\n",
    "+ 主にSIGIR, WWW, ICML, NIPSへの論文に向けたもの\n",
    "\n",
    "## Introduction\n",
    "「情報の洪水に飲み込まれていないかい?」\n",
    "\n",
    "### Webについての真実\n",
    "+ `www.worldwidewebsize.com`によれば, 250億以上のページがウェブ上に存在する.\n",
    "+ 主要な検索エンジンは何百億ものWebページをインデックス化している\n",
    "+ CUIL.com では1200億のウェブページをインデックスづけしている\n",
    "\n",
    "「情報は検索無くして成り立たない」\n",
    "\n",
    "### Ranking is Essential\n",
    "インデックスづけされたドキュメントのレポジトリに対してクエリを投げつける. そのクエリに基づいてランキングモデルが関連度を順序づけてくれる.\n",
    "\n",
    "### Application of Ranking\n",
    "+ document retrieval\n",
    "+ collaborative filtering\n",
    "+ Key term extraction\n",
    "+ Definition finding\n",
    "+ Important email routing\n",
    "+ Sentimant analysis\n",
    "+ Product rating\n",
    "+ Anti Web spam\n",
    "+ etc...\n",
    "\n",
    "いろいろな場面で`ランキング`は利用されている.\n",
    "\n",
    "### Senarios of Ranking\n",
    "ドキュメント検索の具体例\n",
    "+ クエリに対する関連度に基づいて単純にドキュメントをランクづけする\n",
    "+ ドキュメント間の類似性, web構造, 多様性を順序づけの過程で考慮する(相対的ランキング)\n",
    "+ 複数の候補者のランクづけされたリストを集計してより優れた順序リストを生成する\n",
    "+ Webページの属性がどれほどランキング結果に影響を与えるのかを考える\n",
    "\n",
    "### Evaluation of Ranking Results\n",
    "+ ランダムに抽出された多数のクエリから構成されるテストセットを作成し, `relevance judgment`を行う\n",
    "+ テストセットに含まれる特定のクエリに対するランキング結果を`evaluation measure`に基づいて評価する\n",
    "+ テストセット全体への平均的な精度を全体のランキングパフォーマンスとして扱う.\n",
    "\n",
    "### Collecting Documents for A Query\n",
    "+ `TREC`で利用される`Pooling Strategy`\n",
    "  - 関連性があるかもしれないドキュメントを`participating system`から取得する\n",
    "\n",
    "### Relevance Judgment\n",
    "+ Degree of relevance (関連度)\n",
    "  - Binary: relevant vs. irrelevant (関係あり vs. 無関係)\n",
    "  - Multiple ordered categories: Perfect > Excellent > Good > Fair > Bad (段階あり)\n",
    "+ Pairwise preference (1組みで比較)\n",
    "  - \"ドキュメントAはドキュメントBよりもより関連性がある\"\n",
    "+ Total order (全順序)\n",
    "  - 関連度に応じてそのランク{A, B, C, ...}が付与される\n",
    "  \n",
    "### Evaluation Measure\n",
    "関連性の判断についての評価. Judgmentがどれほどよかったかについて.\n",
    "\n",
    "#### MAP\n",
    "+ クエリ$q$について$k$番目の精度\n",
    "    + $P@k = \\frac{上位k件までで関連ありDOCS数}{k}$\n",
    "+ クエリ$q$の`AP (average precision)`は以下のように定義される.\n",
    "$$\n",
    "AP = \\frac{\\sum_{k} P@k \\cdot l_{k}}{関連ありDOCS数}\n",
    "$$\n",
    "\n",
    "例えば, 上位5件が関連(アリ, ナシ, アリ, ナシ, アリ)であった場合...\n",
    "$$\n",
    "AP = \\frac{1}{3} \\cdot (\\frac{1}{1} + \\frac{2}{3} + \\frac{3}{5})\n",
    "$$\n",
    "で計算でき, その値は0.76くらいとなる.\n",
    "\n",
    "ポイントは, 上位$k$件のうち, 関連のあったものだけに対して$P@k$が計算され, \n",
    "$AP$はそれらの和を関連のあるドキュメント数で割ったものとして求められることである.\n",
    "\n",
    "$MAP$は全てのクエリに対しての$AP$の平均値として計算される."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7555555555555555\n",
      "0.7000000000000001\n"
     ]
    }
   ],
   "source": [
    "def precision_at_k(li, k):\n",
    "    \"\"\"\n",
    "    li: @{list of bool} ランキングリスト\n",
    "    k: @{int} 上位k件目\n",
    "    \"\"\"\n",
    "    if li[k-1]:\n",
    "        return sum(li[:k]) / k\n",
    "    return 0\n",
    "\n",
    "def average_precision(li):\n",
    "    return sum([precision_at_k(li, i+1) for i in range(len(li))]) / sum(li)\n",
    "\n",
    "eg_list = [True, False, True, False, True]\n",
    "eg_list_2 = [True, False, False, True, True]\n",
    "print(average_precision(eg_list))\n",
    "print(average_precision(eg_list_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NDCG\n",
    "クエリ$q$に対するランキングの$k$件目までの$DCG$は以下のように計算される. \n",
    "ただし, $rel_{i}$は$i$番目の提案の上位である妥当性を表す.\n",
    "$$\n",
    "DCG_{k} = \\sum_{i=1}^{k} \\frac{2^{rel_{i}} - 1}{log_{2}(i+1)}\n",
    "$$\n",
    "\n",
    "また, $NDCG$は次のように計算される.\n",
    "$$\n",
    "NDCG_{k} = \\frac{DCG_{k}}{idealDCG_{k}}\n",
    "$$\n",
    "\n",
    "例えば, 上位3件のそれぞれのスコアが3, 0, 2である場合は, \n",
    "$$\n",
    "DCG_{3} = \\frac{2^{3} - 1}{log_{2}2} + \\frac{2^{0} - 1}{log_{2}3} + \\frac{2^{2} - 1}{log_{2}4}\\\\\n",
    "DCG_{3} = 5\n",
    "$$\n",
    "\n",
    "となる."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Measure のまとめ\n",
    "+ Position-based: 順位が明示的に利用されている\n",
    "  - より上位のオブジェクトの方が重要\n",
    "  - 関連性の順序 vs. 関連度を表すスコア\n",
    "  - スコアは連続的ではなく, 微分も不可能である場合が多い"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conventional Ranking Models\n",
    "昔昔のはなし. どういうランクモデルがあったのだろうか. その特徴をまとめる.\n",
    "+ Query-dependent\n",
    "  - Boolean model, 拡張版Boolean model\n",
    "  - Vector space model, 潜在意味的インデックス化(LSI)など\n",
    "  - BM25モデル, 統計的言語モデルなど\n",
    "  - Spanベースモデル, 距離集約モデルなど\n",
    "+ Query-independent\n",
    "  - PageRank, TrustRank, BrowseRankなど\n",
    "  \n",
    "このように, クエリに依存する順位づけモデルと依存しない順位づけモデルが存在することがわかる.\n",
    "\n",
    "### 従来モデルの問題\n",
    "+ マニュアル化されたパラメータチューニングが大抵の場合において難しい. \n",
    "  + 特にパラメータの数が多い場合など.\n",
    "+ パラメータチューニングが過学習を引き起こしやすい\n",
    "\n",
    "### Machine Learningを組みこもう\n",
    "+ 機械学習は効果的なツール\n",
    "  + パラメータを自動的にチューニングしてくれる\n",
    "  + いろいろな要因を組み込める\n",
    "  + 正則化などの手法を利用することで過学習を防ぐことができる\n",
    "\n",
    "ここで現れるのが... \"Learning to rank\"!!!\n",
    "\n",
    "一般に, 機械学習を利用したランク学習は`learning to rank`と呼ばれる.\n",
    "\n",
    "## Learning to rank\n",
    "最近の`Learning to rank`に関わる手法から\n",
    "1. 特徴ベース\n",
    "2. 差別的なトレーニング\n",
    "といった性質がある.\n",
    "\n",
    "### 特徴ベース(Feature based)\n",
    "+ ドキュメントは特徴ベクトルとして表現される\n",
    "+ たくさんの特徴量を組み込んで処理を行うことが可能に！\n",
    "\n",
    "### 差別的トレーニング(descriminative training)\n",
    "+ トレーニングデータに基づいた自動的な処理が可能\n",
    "  - `Input space`, `output space`, `hypothesis space`, `loss function`\n",
    "  - 確率論的な説明があまり必要ない\n",
    "+ 現実の検索エンジンで求められている性質\n",
    "  - 数多くのユーザフィードバックやログが存在する\n",
    "  \n",
    "### Learning to rank Framework\n",
    "* * *\n",
    "![フレームワーク](fig01.png)\n",
    "* * *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key questions to answer\n",
    "+ `learning to rank`アルゴリズムは互いにどのように類似し, どのように異なるのか.\n",
    "+ それぞれの強みと弱みはなんだ?\n",
    "+ 調査を行いたいランキングに対するユニークな理論的な問題はなんだ?\n",
    "+ 経験から, どのアルゴリズムがうまくうごくのか?\n",
    "+ 将来的な問題点はなんだ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning to Rank Algorithm\n",
    "+ pointwise アプローチ\n",
    "+ pairwise アプローチ\n",
    "+ listwise アプローチ\n",
    "\n",
    "### Pointwise approach\n",
    "***\n",
    "![pointwise](fig02.png)\n",
    "***\n",
    "\n",
    "#### 具体例\n",
    "+ 以下のランキング生成に応用\n",
    "    + 回帰を利用した`subset ranking`\n",
    "    + 分類\n",
    "        + Discriminative model for IR\n",
    "        + MCRank\n",
    "    + Ordinal regression (順序回帰?)\n",
    "        + `Pranking`\n",
    "        + 最大化マージンランキング\n",
    "\n",
    "##### Subset Ranking using Regression\n",
    "(D. Cossock and T. Zhang, COLT 2006)\n",
    "\n",
    "関連度(relevance degree)を実数値としてみなし, ランキング関数を回帰を利用して学習する. Loss functionを以下のように設定し, 最小化を測る.\n",
    "$$\n",
    "L(f;x_{j}, y_{j}) = |f(x_{j}) - y_{j}|^{2}\n",
    "$$\n",
    "\n",
    "##### Discriminative model for IR\n",
    "ランク学習の段階で分類が利用されている. 関連性のあるドキュメントを正のサンプル(positive example)として利用し, 関連性のないドキュメントを負のサンプル(negative sample)として扱う. ($y_{j} = +1, y_{j} = -1$)\n",
    "$L(f; x_{j}, y_{j})$は0/1損失関数$I_{\\{f(x_{j})\\neq y_{j}\\}}$\n",
    "\n",
    "SVMのhinge関数を利用した最適化アルゴリズムも存在する.\n",
    "\n",
    "##### McRank\n",
    "多クラス分類をランク学習に応用.\n",
    "$$\n",
    "\\hat{y_{j,k}} = P(y_{j} = k), f(x_{j}) = \\sum_{k=0}^{K-1}\\hat{p_{j,k}}k\n",
    "$$\n",
    "\n",
    "#### Pointwiseの問題点\n",
    "+ 関連度がクエリに依存しすぎる場合が存在\n",
    "+ 損失関数においてドキュメントの順位が見えない. ゆえに関連度の薄いものに重要度を割きすぎる場合がある"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Pairwise Approach\n",
    "***\n",
    "![pairwise](fig03.png)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preference function $h(x_{u}, x_{v}) = 2I_{f(x_{u}) \\gt f(x_{v})} - 1$. \n",
    "関数Iは添え字の式が真であれば1, 偽であれば0の値をとる.\n",
    "\n",
    "#### 具体例\n",
    "+ Learning to order things\n",
    "+ RankNet and Frank\n",
    "+ RankBoost\n",
    "+ RankingSVM\n",
    "+ Multi-hyperplane ranker\n",
    "+ IR-SVM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
